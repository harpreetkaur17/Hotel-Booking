{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking only in imporatant features as selected from the previous file \n",
    "## Main purpose is to implement pipleline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from imblearn.metrics import sensitivity_specificity_support\n",
    "from imblearn.metrics import sensitivity_score ,specificity_score\n",
    "from sklearn.metrics import recall_score , accuracy_score ,precision_score,f1_score,roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('hotel_bookings.csv',parse_dates=['reservation_status_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Country , Company ,Ageny ,children has null values\n",
    "## Company has more then 90% null values so Company can be removed easily let us remove and check\n",
    "\n",
    "data.drop('company',axis=1,inplace=True)\n",
    "\n",
    "## after removing Company still children country and Ageny is having null values we will check them later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    75166\n",
       "1    44224\n",
       "Name: is_canceled, dtype: int64"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['is_canceled'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data is imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  0 is max count so let us fill null value of children with 0\n",
    "data.children.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us combine Adults, Children and Babies to one family\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def family(df):\n",
    "    if((df.adults>0) & (df.children>0)):\n",
    "        fam= 1\n",
    "    elif((df.adults>0) & (df.babies>0)):\n",
    "        fam= 1\n",
    "    else:\n",
    "        fam= 0\n",
    "    return fam\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['family']=data.apply(family,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    110281\n",
       "1      9109\n",
       "Name: family, dtype: int64"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['family'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['total_customers']=data.adults+data.children+data.babies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['adults','children','babies'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data.country.fillna('PRT', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "## we can convert previous_cancellations as yes or no\n",
    "data['previous_cancellations']=np.where(data['previous_cancellations']>0,'Yes','No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     112906\n",
       "Yes      6484\n",
       "Name: previous_cancellations, dtype: int64"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['previous_cancellations'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('reservation_status', axis=1 , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('arrival_date_week_number', axis=1 , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('reservation_status_date',axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('agent', axis=1 , inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now our data set is cleaned with 0 null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### arrival_date_day_of_month  and  stays_in_weekend_nights  is very less correlated to is_cancelled so we can remove and try once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['arrival_date_day_of_month', 'stays_in_weekend_nights'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the list of numeric and categorial values saperatly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['July', 'August', 'September', 'October', 'November', 'December',\n",
       "       'January', 'February', 'March', 'April', 'May', 'June'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['arrival_date_month'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "months={'January':1,'February':2,'March':3,'April':4,'May':5,'June':6,'July':7,\n",
    "        'August':8,'September':9,'October':10,'November':11,'December':12}\n",
    "df['arrival_date_month'].replace(months,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['arrival_date_month'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_col=df.select_dtypes(include=['object']).columns\n",
    "numeric_col=df.select_dtypes(include=['number']).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For features with greater than 5 option we will use label encoding and for features less than 5 we will use on hot encoding and for arrival_date_month we will do manually as using label encoder it migth set diff labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installation\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "cat_ser=pd.Series(index=category_col)\n",
    "for i in category_col:\n",
    "    cat_ser[i]=df[i].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hotel                       2.0\n",
       "meal                        5.0\n",
       "country                   177.0\n",
       "market_segment              8.0\n",
       "distribution_channel        5.0\n",
       "previous_cancellations      2.0\n",
       "reserved_room_type         10.0\n",
       "assigned_room_type         12.0\n",
       "deposit_type                3.0\n",
       "customer_type               4.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_var=[]\n",
    "for i in df:\n",
    "    if (df[i].dtype=='O' and (df[i].nunique()==2 or df[i].nunique()>5 )):\n",
    "        lab_var.append(i)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hotel',\n",
       " 'country',\n",
       " 'market_segment',\n",
       " 'previous_cancellations',\n",
       " 'reserved_room_type',\n",
       " 'assigned_room_type']"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hotel\n",
      "country\n",
      "market_segment\n",
      "previous_cancellations\n",
      "reserved_room_type\n",
      "assigned_room_type\n",
      "total_columns updated 6\n"
     ]
    }
   ],
   "source": [
    "lab= LabelEncoder()\n",
    "col_count=0\n",
    "for i in df:\n",
    "    if (df[i].dtype=='O' and (df[i].nunique()==2 or df[i].nunique()>5 )):\n",
    "        if df[i].isnull().any()==False:\n",
    "            lab.fit(df[i])\n",
    "            df[i]=lab.transform(df[i])\n",
    "            print(i)\n",
    "            col_count+=1\n",
    "            \n",
    "print(\"total_columns updated\",col_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int64      12\n",
       "int32       6\n",
       "object      4\n",
       "float64     2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saperating the data set in test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((79991, 23), (39399, 23), (79991,), (39399,))"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=df.drop('is_canceled',axis=1)\n",
    "y=df['is_canceled']\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.33, random_state=42)\n",
    "X_train.shape , X_test.shape , y_train.shape , y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = X_train.select_dtypes(include=['int64','int32', 'float64']).drop(lab_var,axis=1).columns\n",
    "categorical_features = X_train.select_dtypes(include=['object']).columns\n",
    "#lab_features=df.select_dtypes(include=['object']).drop(categorical_features,axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    50412\n",
       "1    29579\n",
       "Name: is_canceled, dtype: int64"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transform=Pipeline(steps=[('imputer',SimpleImputer(strategy='median')),\n",
    "                                 ('scaler',StandardScaler())])\n",
    "\n",
    "#lab_transformer=Pipeline(steps=[('label',LabelEncoder())])\n",
    "onhot_transformer=Pipeline(steps=[('onhot',OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor=ColumnTransformer(transformers=[('num',numeric_transform,numeric_features),\n",
    "                                            ('onhot',onhot_transformer,categorical_features)])\n",
    "\n",
    "classifiers =[LogisticRegression(solver = \"liblinear\"),\n",
    "              LogisticRegression(penalty='l1',solver = \"liblinear\"),\n",
    "              KNeighborsClassifier(),\n",
    "              DecisionTreeClassifier(criterion = 'entropy'),\n",
    "              RandomForestClassifier(n_estimators=58,max_depth=28,max_features=10,min_samples_split=4,min_samples_leaf=1,criterion='gini')\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "model score: 0.780\n",
      "Validation Results\n",
      "Recall score  0.5104131102765449\n",
      "F1 score 0.6329381879762913\n",
      "roc auc score 0.7249084215033044\n",
      "Precision Score 0.8328690807799443\n",
      "Accuracy score :  0.779943653392218\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l1',\n",
      "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "model score: 0.780\n",
      "Validation Results\n",
      "Recall score  0.5097985660635029\n",
      "F1 score 0.6324438797119866\n",
      "roc auc score 0.7246213481525401\n",
      "Precision Score 0.8327941996653653\n",
      "Accuracy score :  0.7797406025533643\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                     weights='uniform')\n",
      "model score: 0.813\n",
      "Validation Results\n",
      "Recall score  0.6947080914988051\n",
      "F1 score 0.7337371989037935\n",
      "roc auc score 0.7885150702302945\n",
      "Precision Score 0.7774126996255827\n",
      "Accuracy score :  0.8125840757379629\n",
      "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
      "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')\n",
      "model score: 0.806\n",
      "Validation Results\n",
      "Recall score  0.7345168999658587\n",
      "F1 score 0.737437444299719\n",
      "roc auc score 0.7910687432688629\n",
      "Precision Score 0.7403813063528116\n",
      "Accuracy score :  0.8055788217975075\n",
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=28, max_features=10,\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=4,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=58,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "model score: 0.848\n",
      "Validation Results\n",
      "Recall score  0.7162854216456128\n",
      "F1 score 0.7780744696632547\n",
      "roc auc score 0.821199186543902\n",
      "Precision Score 0.8515301566685608\n",
      "Accuracy score :  0.8481179725373741\n"
     ]
    }
   ],
   "source": [
    "for classifier in classifiers:\n",
    "    pipe=Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                         ('classifier', classifier)])\n",
    "    pipe.fit(X_train, y_train)   \n",
    "    print(classifier)\n",
    "    print(\"model score: %.3f\" % pipe.score(X_test, y_test))\n",
    "    algo_predict=pipe.predict(X_test)\n",
    "    cm_algo = confusion_matrix(y_test, algo_predict)\n",
    "    algo_acc = accuracy_score(y_test, algo_predict)\n",
    "    print('Validation Results')\n",
    "    print(\"Recall score \",recall_score(y_test, algo_predict))\n",
    "    print(\"F1 score\",f1_score(y_test, algo_predict))\n",
    "    print(\"roc auc score\",roc_auc_score(y_test, algo_predict))\n",
    "    print(\"Precision Score\",precision_score(y_test, algo_predict))\n",
    "    print(\"Accuracy score : \",algo_acc)\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
